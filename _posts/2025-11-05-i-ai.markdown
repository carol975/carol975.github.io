---
title:  I, AI
layout: single
date:   2025-11-05 00:51:00 -0800
read_time: true
tags:
    - ai
    - llm
    - tech
---

I’ve always wanted to write something about AI, but work, life, and endless phone scrolling in the bathroom have taken priority. I really had to talk myself out of this habitual procrastination. Only now, on the last week of my vacation, have I finally sat down with my hands on the keyboard to begin collecting my thoughts on this AI thing. 

“AI” products have existed for decades, but they mostly remained in the hands of tech developers and business entrepreneurs. It was only at the end of 2022 when the explosive emergence of ChatGPT brought AI to everyone’s hands. I first heard about ChatGPT from my coworkers, but never took the opportunity to try it until mid-2023. I was finally fed up with people telling me “Carol, you should totally try it!” and decided to open up ChatGPT's website. 

Like the majority of people, I approached the LLM agent like Google. I asked about the weather, then asked it to make me a diet and exercise plan, plus some advice on financial management. It answered all questions almost perfectly after a few rounds of prompts. Welp, I thought, this is useful. I then tried asking it to write a test for a piece of code, a task that I find to be utterly tedious and time-consuming, and it quickly spat out a few lines that I could paste into my repo and run. Hooray! There is nothing better than this! Very soon I found myself asking all questions on ChatGPT instead of Google. Stack Overflow? That’s my ex now. 

Although ChatGPT was super useful, I was still quite hesitant to copy and paste code it generated. Since elementary school, we were taught to always quote or paraphrase and cite our sources. I didn’t want to plagiarize, even if it was created by a non-living entity, whether out of work ethic or human pride. I also had another concern, does copying and pasting rob me of the opportunity to think with my own brain, making me potentially less sharp in the future? I think I started observing that happening. 

Writing was never my forte. Even for short Slack messages, I often have to think and struggle for at least ten minutes before sending. I fear using the wrong vocabulary and grammar. Then one day I decided to throw one of my half-baked messages to ChatGPT. Without a single additional prompt, it guessed my intention and rephrased the writing into something that sounded much less awkward, more accurate and more formal — well polished! “Aha, this is much better and must be the correct way to write it,” I exclaimed, in awe and wonder. Without hesitation I pasted that into Slack and hit send. 

Ever since then, I developed the habit of having ChatGPT check every single writing before sending. Until one day it hit me. I realized that by default I assume my own writing is not good enough and ChatGPT would always provide the correct version. ChatGPT’s version looked nicer but it was not how I would say things. It didn’t feel like I was the one communicating and building those relationships anymore, rather it felt like someone else was speaking for me, That felt weird and wrong. I then stopped using ChatGPT for Slack messages. I knew my grammar and word choice could be awkward, but I don’t have to be always writing correctly. I had the ability to communicate accurately with my coworker before using ChatGPT, so I really shouldn’t doubt my capability to continue communicating accurately with my original writing. I didn’t need to lose confidence in myself. 
But I’ve gotten smarter. For longer writing, such as tech specs or emails, I try to brainstorm and complete the writing on my own. Then ask ChatGPT to review and give advice, but not rewrite it for me. Then based on the feedback I would try to come up with amendments myself, much like having a high school English teacher marking an essay pointing out where and how I could write better. In the end I will be the one whose writing really improves. 

Back in summer 2017, while I was an intern at a robotics laboratory in Japan, I had a conversation with my supervisor Dylan about AI. I brought up how, in the previous year, AlphaGo had beaten Lee Sedol in Go. In any human-to-human competition, winning has meaning, because it brings a sense of personal pride and collective honour — pride comes from knowing you have achieved something remarkable, while honour is shared with fellow humans as standards are raised. Losing has value, too: you can study the winner’s strategy, refine your approach, and aim to win the next one. For these reasons humans are propelled to keep striving to reach higher ground. 

But AI, the perfect know-it-all, will very soon surpass humans in almost all areas and evolve to be invincible. At that point all of these human-pride-rooted achievements will become utterly meaningless! No matter how high humans try to jump, there will always be an AI up there. Oh, that would take so much meaning away from our lives. To which Dylan, the optimistic roboticist, replied, “No I don’t think so. AI could become our teacher; we would learn from AI so that we can improve ourselves.” That took me a while to digest. I think I still am. With the evolution of AI, there won’t be a way to be the best of the best.  But there will always be ways to improve, so we can be the best version of ourselves. Is that a good or bad thing? I’m not sure. We humans are ambitious and greedy creatures. Are we willing to settle for that?

Perhaps one day I will know the answer, but for now I will keep writing and editing, following AI’s teaching. 
